{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json, time, os, gc, math\n",
    "import datetime\n",
    "from tqdm import tqdm \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "import keras.backend as K  \n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam \n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from gensim.models import word2vec \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "# from utils.opt import AdamW, RAdam\n",
    "import logging\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "gpus = os.environ['CUDA_VISIBLE_DEVICES'].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:         112298        3592       91298          18       17407      108529\n",
      "Swap:             0           0           0\n",
      "Sun Jul 12 12:13:29 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   27C    P8     9W / 250W |      0MiB / 22919MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   28C    P8     9W / 250W |      0MiB / 22919MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!free -m\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 150\n",
    "w2v_size = 300\n",
    "batch_size = 512\n",
    "random_seed = 2020\n",
    "drop_p = 0.20\n",
    "sp_drop = 0.20\n",
    "l2_rate = 1e-5\n",
    "model_name = 'bilstm_attr_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:13:38 : bilstm_attr_v1\n",
      "\n",
      "12:15:52 : data loaded\n",
      "\n",
      "CPU times: user 36 ms, sys: 13.9 s, total: 13.9 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "file_name = \"data/log/\"+datetime.date.today().strftime('%m%d')+\"_{}.log\".format(model_name)\n",
    "def write_log(w):\n",
    "    t0 = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\\n\".format(t0, w)\n",
    "    print(info)\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(info)\n",
    "        f.write(\"-\"*80+\"\\n\")\n",
    "write_log(model_name)\n",
    "\n",
    "creative_id_emb_matrix = np.load(\"data/cid_weight_300d.npy\")\n",
    "ad_id_emb_matrix = np.load(\"data/adid_weight_300d.npy\")\n",
    "product_id_emb_matrix = np.load(\"data/pid_weight_300d.npy\")\n",
    "advertiser_id_emb_matrix = np.load(\"data/ader_weight_300d.npy\")\n",
    "\n",
    "train_cid = np.load(\"data/nn_data/train_cid.npy\")\n",
    "train_ader = np.load(\"data/nn_data/train_ader.npy\")\n",
    "train_adid = np.load(\"data/nn_data/train_adid.npy\")\n",
    "train_pid = np.load(\"data/nn_data/train_pid.npy\")\n",
    "train_pcat = np.load(\"data/nn_data/train_pcat.npy\")\n",
    "train_ind = np.load(\"data/nn_data/train_ind.npy\")\n",
    "\n",
    "# train_age = np.load(\"data/nn_data/train_age.npy\")\n",
    "train_gender = np.load(\"data/nn_data/train_gender.npy\")\n",
    "write_log(\"data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 4.57 s, total: 6.46 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_cid = train_cid.astype(np.int32)\n",
    "train_ader = train_ader.astype(np.int32)\n",
    "train_adid = train_adid.astype(np.int32)\n",
    "train_pid = train_pid.astype(np.int32)\n",
    "train_pcat = train_pcat.astype(np.int32)\n",
    "train_ind = train_ind.astype(np.int32)\n",
    "\n",
    "# train_age = train_age.astype(np.int32)\n",
    "train_gender = train_gender.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:         112298       23517       51455          18       37325       88605\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1234).split(train_cid, train_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 2999995 2999997 2999999] [     17      21      30 ... 2999992 2999996 2999998]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [     20      32      44 ... 2999926 2999936 2999995]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [     19      22      24 ... 2999980 2999991 2999994]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [      6      11      40 ... 2999949 2999952 2999955]\n",
      "[      0       1       2 ... 2999996 2999997 2999998] [     12      15      29 ... 2999986 2999988 2999999]\n",
      "[      2       3       4 ... 2999996 2999998 2999999] [      0       1      25 ... 2999976 2999979 2999997]\n",
      "[      0       1       3 ... 2999997 2999998 2999999] [      2       5       7 ... 2999981 2999984 2999987]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [      4       8      18 ... 2999954 2999961 2999985]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [     10      16      26 ... 2999967 2999968 2999983]\n",
      "[      0       1       2 ... 2999997 2999998 2999999] [      3       9      14 ... 2999969 2999989 2999993]\n"
     ]
    }
   ],
   "source": [
    "for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "    print(trn_idx, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern_reg = regularizers.l2(l2_rate)\n",
    "class Attention(Layer):\n",
    "    \"\"\"多头自注意力机制\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_head, size_per_head, **kwargs):\n",
    "        self.nb_head = nb_head\n",
    "        self.size_per_head = size_per_head\n",
    "        self.out_dim = nb_head * size_per_head\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        super(Attention, self).build(input_shape)\n",
    "        q_in_dim = input_shape[0][-1]\n",
    "        k_in_dim = input_shape[1][-1]\n",
    "        v_in_dim = input_shape[2][-1]\n",
    "        self.q_kernel = self.add_weight(name='q_kernel',\n",
    "                                        shape=(q_in_dim, self.out_dim),\n",
    "                                        regularizer= kern_reg,\n",
    "                                        initializer='glorot_normal')\n",
    "        self.k_kernel = self.add_weight(name='k_kernel',\n",
    "                                        shape=(k_in_dim, self.out_dim),\n",
    "                                        regularizer= kern_reg,\n",
    "                                        initializer='glorot_normal')\n",
    "        self.v_kernel = self.add_weight(name='w_kernel',\n",
    "                                        shape=(v_in_dim, self.out_dim),\n",
    "                                        regularizer= kern_reg,\n",
    "                                        initializer='glorot_normal')\n",
    "    def mask(self, x, mask, mode='mul'):\n",
    "        if mask is None:\n",
    "            return x\n",
    "        else:\n",
    "            for _ in range(K.ndim(x) - K.ndim(mask)):\n",
    "                mask = K.expand_dims(mask, K.ndim(mask))\n",
    "            if mode == 'mul':\n",
    "                return x * mask\n",
    "            else:\n",
    "                return x - (1 - mask) * 1e10\n",
    "    def call(self, inputs):\n",
    "        q, k, v = inputs[:3]\n",
    "        v_mask, q_mask = None, None\n",
    "        if len(inputs) > 3:\n",
    "            v_mask = inputs[3]\n",
    "            if len(inputs) > 4:\n",
    "                q_mask = inputs[4]\n",
    "        # 线性变换\n",
    "        qw = K.dot(q, self.q_kernel)\n",
    "        kw = K.dot(k, self.k_kernel)\n",
    "        vw = K.dot(v, self.v_kernel)\n",
    "        # 形状变换\n",
    "        qw = K.reshape(qw, (-1, K.shape(qw)[1], self.nb_head, self.size_per_head))\n",
    "        kw = K.reshape(kw, (-1, K.shape(kw)[1], self.nb_head, self.size_per_head))\n",
    "        vw = K.reshape(vw, (-1, K.shape(vw)[1], self.nb_head, self.size_per_head))\n",
    "        # 维度置换\n",
    "        qw = K.permute_dimensions(qw, (0, 2, 1, 3))\n",
    "        kw = K.permute_dimensions(kw, (0, 2, 1, 3))\n",
    "        vw = K.permute_dimensions(vw, (0, 2, 1, 3))\n",
    "        # Attention\n",
    "        a = K.batch_dot(qw, kw, [3, 3]) / self.size_per_head**0.5\n",
    "        a = K.permute_dimensions(a, (0, 3, 2, 1))\n",
    "        a = self.mask(a, v_mask, 'add')\n",
    "        a = K.permute_dimensions(a, (0, 3, 2, 1))\n",
    "        a = K.softmax(a)\n",
    "        # 完成输出\n",
    "        o = K.batch_dot(a, vw, [3, 2])\n",
    "        o = K.permute_dimensions(o, (0, 2, 1, 3))\n",
    "        o = K.reshape(o, (-1, K.shape(o)[1], self.out_dim))\n",
    "        o = self.mask(o, q_mask, 'mul')\n",
    "        return o\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern_reg = regularizers.l2(l2_rate)\n",
    "def get_model(input_len, emb_size, drop_p=0.2, sp_drop=0.2): \n",
    "    cid = Input(shape=(input_len, ), name='cid')\n",
    "    adid = Input(shape=(input_len, ), name='adid')\n",
    "    aderid = Input(shape=(input_len, ), name='aderid')\n",
    "    prodid = Input(shape=(input_len, ), name='prodid')\n",
    "    # timeid = Input(shape=(input_len, ), name='timeid')\n",
    "    pcid = Input(shape=(input_len, ), name='pcid')\n",
    "    inid = Input(shape=(input_len, ), name='inid')\n",
    "    \n",
    "#     clk_times = Input(shape=(input_len, ), name='clk_times')\n",
    "    \n",
    "    emb0 = Embedding(creative_id_emb_matrix.shape[0], creative_id_emb_matrix.shape[1],\n",
    "                      weights=[creative_id_emb_matrix], trainable=False)(cid)\n",
    "    emb1 = Embedding(ad_id_emb_matrix.shape[0], ad_id_emb_matrix.shape[1],\n",
    "                      weights=[ad_id_emb_matrix], trainable=False)(adid)\n",
    "    emb2 = Embedding(advertiser_id_emb_matrix.shape[0], advertiser_id_emb_matrix.shape[1],\n",
    "                      weights=[advertiser_id_emb_matrix], trainable=False)(aderid)\n",
    "    emb3 = Embedding(product_id_emb_matrix.shape[0], product_id_emb_matrix.shape[1],\n",
    "                      weights=[product_id_emb_matrix], trainable=False)(prodid)\n",
    "    \n",
    "#     emb4 = Embedding(92, 18, embeddings_regularizer=kern_reg)(timeid)\n",
    "    emb5 = Embedding(20, 50, embeddings_regularizer=kern_reg)(pcid)\n",
    "    emb6 = Embedding(338, 100, embeddings_regularizer=kern_reg)(inid)\n",
    "    \n",
    "    sdrop = SpatialDropout1D(sp_drop)\n",
    "    x = Concatenate()([sdrop(emb0), sdrop(emb1), sdrop(emb2), sdrop(emb3), sdrop(emb5), sdrop(emb6)])\n",
    "    \n",
    "    # x = Dropout(drop_p)(Bidirectional(CuDNNGRU(128, return_sequences=True))(x))\n",
    "    x = Dropout(drop_p)(Bidirectional(CuDNNGRU(256, return_sequences=True))(x))\n",
    "    # x2 = Dropout(drop_p)(Bidirectional(CuDNNGRU(50, return_sequences=True))(x))\n",
    "    # x = Concatenate()([x1, x2])\n",
    "    #mask = Lambda(lambda x: K.cast(K.greater(K.expand_dims(x, 2), 0), 'float32'))(cid)\n",
    "    #x = Attention(8, 32)([x, x, x, mask])\n",
    "    x = TimeDistributed(Dense(256, activation=\"tanh\"))(x)\n",
    "    x_max = Lambda(lambda x: K.max(x, axis=1), output_shape=(256,))(x)\n",
    "    x_avg = Lambda(lambda x: K.mean(x, axis=1), output_shape=(256,))(x)\n",
    "    \n",
    "    dnn_input = Concatenate()([x_max, x_avg])\n",
    "    output = Dropout(0.2)(Dense(512, activation='relu')(dnn_input))\n",
    "    output = Dense(256, activation='relu')(output)\n",
    "    pred = Dense(2, activation=\"softmax\")(output)\n",
    "    \n",
    "    return Model(inputs=[cid, aderid, adid, prodid, pcid, inid], outputs=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 150) (1000000, 150) (1000000, 150)\n",
      "CPU times: user 20 ms, sys: 2.29 s, total: 2.31 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_cid = np.load(\"data/nn_data/test_cid.npy\")\n",
    "test_ader = np.load(\"data/nn_data/test_ader.npy\")\n",
    "test_adid = np.load(\"data/nn_data/test_adid.npy\")\n",
    "test_pid = np.load(\"data/nn_data/test_pid.npy\")\n",
    "test_pcat = np.load(\"data/nn_data/test_pcat.npy\")\n",
    "test_ind = np.load(\"data/nn_data/test_ind.npy\")\n",
    "\n",
    "print(test_cid.shape, test_pid.shape, test_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_gender = keras.utils.to_categorical(train_gender)\n",
    "print(train_gender.shape)\n",
    "\n",
    "pred_test_gender = np.zeros((test_cid.shape[0], 2))\n",
    "oof_train = np.zeros((train_cid.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:32:20 : fold : 0\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 2700000 samples, validate on 300000 samples\n",
      "Epoch 1/40\n",
      "2700000/2700000 [==============================] - 1064s 394us/step - loss: 0.1623 - acc: 0.9431 - val_loss: 0.1505 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94745, saving model to save_model/gender_bigru_fold_1.h5\n",
      "Epoch 2/40\n",
      "2700000/2700000 [==============================] - 1021s 378us/step - loss: 0.1527 - acc: 0.9470 - val_loss: 0.1483 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94745 to 0.94846, saving model to save_model/gender_bigru_fold_1.h5\n",
      "Epoch 3/40\n",
      "2700000/2700000 [==============================] - 1021s 378us/step - loss: 0.1490 - acc: 0.9483 - val_loss: 0.1478 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94846 to 0.94861, saving model to save_model/gender_bigru_fold_1.h5\n",
      "Epoch 4/40\n",
      "2700000/2700000 [==============================] - 1021s 378us/step - loss: 0.1461 - acc: 0.9495 - val_loss: 0.1469 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94861\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/40\n",
      "2700000/2700000 [==============================] - 1022s 378us/step - loss: 0.1402 - acc: 0.9517 - val_loss: 0.1464 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94861 to 0.94906, saving model to save_model/gender_bigru_fold_1.h5\n",
      "Epoch 6/40\n",
      "2700000/2700000 [==============================] - 1022s 378us/step - loss: 0.1314 - acc: 0.9550 - val_loss: 0.1475 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94906\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 00007: early stopping\n",
      "14:36:48 : {'val_loss': [0.1504612596988678, 0.14832194082419078, 0.14784453315893809, 0.1469043929862976, 0.14635630819002787, 0.14727384873231253, 0.14751374756177266], 'val_acc': [0.9474533333778381, 0.9484599999554952, 0.9486133333206177, 0.9485400000445048, 0.9490633333778381, 0.9488999999872844, 0.9488499999936422], 'loss': [0.16233664234373305, 0.152679131798391, 0.1490131522764983, 0.14608561991850535, 0.14016532696397216, 0.13676797177297098, 0.13142463709442703], 'acc': [0.9430774074074074, 0.9469537037015844, 0.948311481480775, 0.9495251851837724, 0.9517074074088202, 0.9530133333354526, 0.9550403703703704], 'lr': [0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.00025]}\n",
      "\n",
      "300000/300000 [==============================] - 52s 175us/step\n",
      "1000000/1000000 [==============================] - 173s 173us/step\n",
      "14:40:54 : fold : 1\n",
      "\n",
      "Train on 2700000 samples, validate on 300000 samples\n",
      "Epoch 1/40\n",
      "2700000/2700000 [==============================] - 1025s 380us/step - loss: 0.1623 - acc: 0.9430 - val_loss: 0.1533 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94739, saving model to save_model/gender_bigru_fold_2.h5\n",
      "Epoch 2/40\n",
      "2700000/2700000 [==============================] - 1024s 379us/step - loss: 0.1528 - acc: 0.9469 - val_loss: 0.1504 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94739 to 0.94832, saving model to save_model/gender_bigru_fold_2.h5\n",
      "Epoch 3/40\n",
      "2700000/2700000 [==============================] - 1024s 379us/step - loss: 0.1489 - acc: 0.9483 - val_loss: 0.1484 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94832 to 0.94899, saving model to save_model/gender_bigru_fold_2.h5\n",
      "Epoch 4/40\n",
      "2700000/2700000 [==============================] - 1025s 379us/step - loss: 0.1461 - acc: 0.9494 - val_loss: 0.1485 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94899\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/40\n",
      "2700000/2700000 [==============================] - 1024s 379us/step - loss: 0.1404 - acc: 0.9515 - val_loss: 0.1469 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94899 to 0.94958, saving model to save_model/gender_bigru_fold_2.h5\n",
      "Epoch 6/40\n",
      " 174080/2700000 [>.............................] - ETA: 15:07 - loss: 0.1384 - acc: 0.9526"
     ]
    }
   ],
   "source": [
    "for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "   \n",
    "    write_log(\"fold : {}\".format(idx))\n",
    "    K.clear_session()\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = get_model(maxlen, w2v_size, drop_p, sp_drop)\n",
    "        # print(model.summary())\n",
    "\n",
    "    if len(gpus)>=2:\n",
    "        model = multi_gpu_model(model, gpus=len(gpus))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "    filepath = \"save_model/gender_bigru_fold_{}.h5\".format(idx+1)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, min_lr=0.00005, verbose=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_acc', min_delta=0.000001, patience=2, verbose=1, mode='max')\n",
    "    callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    \n",
    "    hist = model.fit([train_cid[trn_idx], train_ader[trn_idx], train_adid[trn_idx], \n",
    "                      train_pid[trn_idx], train_pcat[trn_idx], train_ind[trn_idx]], train_gender[trn_idx], \n",
    "                     validation_data=([train_cid[val_idx], train_ader[val_idx], train_adid[val_idx],\n",
    "                                        train_pid[val_idx], train_pcat[val_idx], train_ind[val_idx]], train_gender[val_idx]),\n",
    "                     epochs=40, batch_size=512, callbacks=callbacks, verbose=1)\n",
    "    write_log(str(hist.history))\n",
    "    \n",
    "    model.load_weights(\"save_model/gender_bigru_fold_{}.h5\".format(idx+1))\n",
    "    oof_train[val_idx] = model.predict([train_cid[val_idx], train_ader[val_idx], train_adid[val_idx],\n",
    "                                        train_pid[val_idx], train_pcat[val_idx], train_ind[val_idx]], batch_size=1024, verbose=1)\n",
    "    per_pred = model.predict([test_cid, test_ader, test_adid, test_pid, test_pcat, test_ind], \n",
    "                             batch_size=1024, verbose=1)\n",
    "    \n",
    "    pred_test_gender += per_pred / len(splits)\n",
    "#     break\n",
    "\n",
    "np.save(\"data/nn_data/oof_train_gender_bigru.npy\", oof_train)\n",
    "np.save(\"data/nn_data/pred_test_gender_bigru.npy\", pred_test_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:36:34 : fold : 0\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "300000/300000 [==============================] - 61s 203us/step\n",
      "1000000/1000000 [==============================] - 187s 187us/step\n",
      "01:42:27 : fold : 1\n",
      "\n",
      "300000/300000 [==============================] - 57s 189us/step\n",
      "1000000/1000000 [==============================] - 189s 189us/step\n",
      "01:48:19 : fold : 2\n",
      "\n",
      "300000/300000 [==============================] - 57s 190us/step\n",
      "1000000/1000000 [==============================] - 189s 189us/step\n",
      "01:54:11 : fold : 3\n",
      "\n",
      "300000/300000 [==============================] - 57s 189us/step\n",
      "1000000/1000000 [==============================] - 188s 188us/step\n",
      "02:00:03 : fold : 4\n",
      "\n",
      "300000/300000 [==============================] - 57s 190us/step\n",
      "1000000/1000000 [==============================] - 188s 188us/step\n",
      "02:05:55 : fold : 5\n",
      "\n",
      "300000/300000 [==============================] - 56s 188us/step\n",
      "1000000/1000000 [==============================] - 188s 188us/step\n",
      "02:11:45 : fold : 6\n",
      "\n",
      "300000/300000 [==============================] - 57s 188us/step\n",
      "1000000/1000000 [==============================] - 187s 187us/step\n",
      "02:17:35 : fold : 7\n",
      "\n",
      "300000/300000 [==============================] - 57s 190us/step\n",
      "1000000/1000000 [==============================] - 189s 189us/step\n",
      "02:23:28 : fold : 8\n",
      "\n",
      "300000/300000 [==============================] - 57s 191us/step\n",
      "300000/300000 [==============================] - 57s 190us/step\n",
      " 402432/1000000 [===========>..................] - ETA: 1:52"
     ]
    }
   ],
   "source": [
    "for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "\n",
    "    write_log(\"fold : {}\".format(idx))\n",
    "    K.clear_session()\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = get_model(maxlen, w2v_size, drop_p, sp_drop)\n",
    "        # print(model.summary())\n",
    "        \n",
    "    if len(gpus)>=2:\n",
    "        model = multi_gpu_model(model, gpus=len(gpus))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "#     filepath = \"best_model_bilstm_fold_{}.h5\".format(idx+1)\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "#     reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1, min_lr=0.00005, verbose=1)\n",
    "#     earlystopping = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=2, verbose=1, mode='max')\n",
    "#     callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    \n",
    "#     hist = model.fit([train_cid[trn_idx], train_ader[trn_idx], train_adid[trn_idx], \n",
    "#                       train_pid[trn_idx], train_pcat[trn_idx], train_ind[trn_idx]], train_age[trn_idx], \n",
    "#                      validation_data=([train_cid[val_idx], train_ader[val_idx], train_adid[val_idx],\n",
    "#                                         train_pid[val_idx], train_pcat[val_idx], train_ind[val_idx]], train_age[val_idx]),\n",
    "#                      epochs=40, batch_size=512, callbacks=callbacks, verbose=1)\n",
    "#     write_log(str(hist.history))\n",
    "    \n",
    "    model.load_weights(\"best_model_gender_fold_{}.h5\".format(idx+1))\n",
    "    oof_train[val_idx] = model.predict([train_cid[val_idx], train_ader[val_idx], train_adid[val_idx],\n",
    "                                        train_pid[val_idx], train_pcat[val_idx], train_ind[val_idx]], batch_size=1024, verbose=1)\n",
    "    per_pred = model.predict([test_cid, test_ader, test_adid, test_pid, test_pcat, test_ind], \n",
    "                             batch_size=1024, verbose=1)\n",
    "    \n",
    "    pred_test_age += per_pred / len(splits)\n",
    "# #     break\n",
    "\n",
    "np.save(\"data/nn_data/oof_train.npy\", oof_train)\n",
    "np.save(\"data/nn_data/pred_test_age.npy\", pred_test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "0.949405\n",
      "round:  2\n",
      "[1.0, 1.01]\n"
     ]
    }
   ],
   "source": [
    "# ```PYTHON\n",
    "####opt\n",
    "class_num=2\n",
    "weights = [1.0]*class_num\n",
    "\n",
    "def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "    weight = init_weight.copy()\n",
    "    f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(axis=1))\n",
    "    flag_score = 0\n",
    "    round_num = 1\n",
    "    while(flag_score != f_best):\n",
    "        print(\"round: \", round_num)\n",
    "        round_num += 1\n",
    "        flag_score = f_best\n",
    "        for c in range(class_num):\n",
    "            for n_w in range(0, 2000,10):\n",
    "                num = n_w * step\n",
    "                new_weight = weight.copy()\n",
    "                new_weight[c] = num\n",
    "\n",
    "                prob_df = raw_prob.copy()\n",
    "                prob_df = prob_df * np.array(new_weight)\n",
    "\n",
    "                f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(axis=1))\n",
    "                if f > f_best:\n",
    "                    weight = new_weight.copy()\n",
    "                    f_best = f\n",
    "                    print(f)\n",
    "    return weight\n",
    "\n",
    "weight = search_weight(train_gender.argmax(-1), oof_train)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_train = np.load(\"data/nn_data/oof_train_gender.npy\")\n",
    "pred_gender_gru = np.load(\"data/nn_data/pred_test_gender_bigru.npy\")\n",
    "pred_gender_lstm = np.load(\"data/nn_data/pred_test_gender_bilstm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gender = pred_gender_gru * 0.5 + pred_gender_lstm * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9494043333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train_gender.argmax(-1), oof_train.argmax(-1)))\n",
    "# print(accuracy_score(train_gender.argmax(-1), (weight*oof_train).argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight = np.array([0.96, 1.03, 1.0, 1.0, 1.0, 0.99, 1.0, 0.99, 1.0, 0.88])\n",
    "weight = np.array([0.82, 0.97, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88, 0.97, 1.01])\n",
    "pred_test_age = pred_test_age * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/1000000 [==============================] - 171s 171us/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict([test_cid, test_ader, test_pid], batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age = np.argmax(pred_test_age, axis=1) + 1\n",
    "gender = np.argmax(pred_gender, axis=1) + 1\n",
    "test_submit = pd.read_csv(\"data/submit/post_process_2.csv\")\n",
    "test_submit['predicted_age'] += 10\n",
    "test_submit['predicted_gender'] = gender\n",
    "#np.save(filename+\".npy\", pred_test_age)\n",
    "test_submit.to_csv(\"data/submit/B_gender_10fold_gru_lstnm.csv\", header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000001</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000002</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000003</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000004</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000005</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3999996</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>3999997</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>3999998</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>3999999</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  predicted_age  predicted_gender\n",
       "0       3000001              3                 6\n",
       "1       3000002              7                 7\n",
       "2       3000003              3                 7\n",
       "3       3000004              3                 6\n",
       "4       3000005              4                 6\n",
       "...         ...            ...               ...\n",
       "999995  3999996              2                 6\n",
       "999996  3999997              2                 6\n",
       "999997  3999998              2                 6\n",
       "999998  3999999              3                 6\n",
       "999999  4000000              4                 6\n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_age_pred_zhan = np.load(\"data/submit/age.npy\")\n",
    "test_gender_pred = np.load(\"data/submit/gender.npy\")\n",
    "test_age_pred_cong = np.load(\"data/nn_data/pred_test_age.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gender_pred = (test_gender_pred > 0.5) + 1\n",
    "test_gender_pred = test_gender_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gender_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_age_pred = test_age_pred_zhan * 0.5 + test_age_pred_cong * 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.argmax(test_age_pred, axis=1) + 1\n",
    "test_submit = pd.read_csv(\"data/submit/post_process_2.csv\")\n",
    "test_submit['predicted_age'] = age\n",
    "test_submit['predicted_gender'] = test_gender_pred\n",
    "#np.save(filename+\".npy\", pred_test_age)\n",
    "test_submit.to_csv(\"data/submit/B_bilstm_10fold_ronghe.csv\", header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4006668800 1 3 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
